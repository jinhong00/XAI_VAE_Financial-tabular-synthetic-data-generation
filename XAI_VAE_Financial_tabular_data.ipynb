{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare\n",
        "\n",
        "Before you start this notebook. Complete the following steps:\n",
        "\n",
        "1. create a dir in the /content, named by \"data\"\n",
        "2. upload the csv file to \"/content/data\""
      ],
      "metadata": {
        "id": "mR_i1-IRZRVq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwb5xyeZeCu6"
      },
      "outputs": [],
      "source": [
        "!pip install category-encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpYEYN5rp0Rk"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow.compat.v1 as tf # to make it work with tf2.0\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sklearn\n",
        "from numpy.random import seed # to randomize sensitive client information\n",
        "from numpy.random import randint # to randomize sensitive client information\n",
        "from category_encoders import TargetEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "tf.enable_eager_execution() \n",
        "train_loss = tf.keras.metrics.Mean()\n",
        "val_loss = tf.keras.metrics.Mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmKsrkjNp57W"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yer638Qp7ZS"
      },
      "outputs": [],
      "source": [
        "TRAIN_BUF = 100000 \n",
        "BATCH_SIZE = 512\n",
        "INPUT_DIM=19\n",
        "COMPRESSION_FACTOR=(3/4)\n",
        "LATENT_DIM= int(COMPRESSION_FACTOR*INPUT_DIM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMNVgKz4bRCA"
      },
      "source": [
        "# Data process\n",
        "\n",
        "This part is used to pre-process the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7ecJ7Zfbeko"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df = train_data.groupby(train_data.columns[-1])\n",
        "grouped_df.size().plot(kind='bar',color=[(0.2,0.4,0.6),(0.8,0.5,0)])\n",
        "\n",
        "plt.xlabel('Subscribe to a term deposit')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.xticks(range(len(grouped_df.groups)), ['no', 'yes'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25tqpoLdM5ML",
        "outputId": "c848fe10-dea1-4ba4-dd69-76f005de3b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plou-j0ebes4"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G0xQdK2bev0"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL-TW6qvcKHE"
      },
      "outputs": [],
      "source": [
        "category_col = [col for col in train_data.columns.tolist() if train_data[col].dtype == object]\n",
        "print(category_col)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "JgnojjjvSGEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in category_col:\n",
        "    lc = LabelEncoder()\n",
        "    train_data[col] = lc.fit_transform(train_data[col])"
      ],
      "metadata": {
        "id": "5uuFGCbuSJyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "id": "SY2L3MWoVSCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data.drop(\"y\", axis=1)\n",
        "y = train_data['y']"
      ],
      "metadata": {
        "id": "MaJ63aBFSbTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caMTPPY3guTE"
      },
      "source": [
        "## Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA3m4JI0d-jY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTqhp8n_d-m4"
      },
      "outputs": [],
      "source": [
        "x = MinMaxScaler().fit_transform(X)\n",
        "x = pd.DataFrame(data=x, columns=X.columns.tolist())\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny23Ola6hdzU"
      },
      "outputs": [],
      "source": [
        "# Save the processed data to csv file\n",
        "x.to_csv(\"/content/data/processed_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8HLp_WTSznS"
      },
      "outputs": [],
      "source": [
        "y.to_csv(\"/content/data/y.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJTMIbxjqo3x"
      },
      "source": [
        "# load processed data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    training_set = None\n",
        "    with open(\"/content/data/processed_data.csv\", mode=\"r\") as f:\n",
        "        training_set = pd.read_csv(f)\n",
        "    return training_set\n",
        "\n",
        "\n",
        "def create_complete_data():\n",
        "    training_set = load_data()\n",
        "    size = training_set.shape\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(tf.constant(training_set.values, dtype = tf.float32, shape=size))\n",
        "    input = train_dataset\n",
        "    train_dataset = train_dataset.shuffle(TRAIN_BUF)\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "    return train_dataset"
      ],
      "metadata": {
        "id": "q7pU1a8oE8zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHbI43ZbqWZu"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HERhoWplqQH-"
      },
      "outputs": [],
      "source": [
        "class TVAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim, input_dim):\n",
        "        super(TVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.inference_net = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
        "            tf.keras.layers.Dense(units=input_dim, activation=tf.nn.tanh),\n",
        "            tf.keras.layers.Dense(units=latent_dim, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Dense(units=latent_dim + latent_dim),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "        self.generative_net = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(units=latent_dim, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Dense(units=input_dim, activation=tf.nn.tanh),\n",
        "            tf.keras.layers.Dense(units=input_dim),\n",
        "            \n",
        "        ]\n",
        "    )\n",
        "\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random_normal(shape=(100, self.latent_dim))\n",
        "        return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "    def encode(self, x):\n",
        "        model_output = self.inference_net(x)\n",
        "        mean, logvar = tf.split(model_output, num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random_normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.generative_net(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2HRwkhqZNf"
      },
      "source": [
        "# Computing Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUTgpfwMqb8w"
      },
      "outputs": [],
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.log(2. * np.pi)\n",
        "    return tf.reduce_sum(\n",
        "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "        axis=raxis)\n",
        "\n",
        "def mean_squared_error(logit, ground_truth):\n",
        "    error = (ground_truth - logit)\n",
        "    MSE = tf.reduce_mean(tf.square(error), axis=1)\n",
        "    return MSE\n",
        "\n",
        "def compute_loss(model, x):\n",
        "    mean, logvar = model.encode(x)\n",
        "   \n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    x_logit = model.decode(z)\n",
        "    x = tf.reshape(x, x_logit.shape)\n",
        "\n",
        "    MSE = mean_squared_error(logit=x_logit, ground_truth=x)\n",
        "    logpx_z = -tf.reduce_sum(MSE, axis=0)\n",
        "\n",
        "    logpz = log_normal_pdf(z, 0., 0.)\n",
        "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "    \n",
        "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "def compute_gradients(model, x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, x)\n",
        "    return tape.gradient(loss, model.trainable_variables), loss\n",
        "\n",
        "def apply_gradients(optimizer, gradients, variables, global_step=None):\n",
        "    optimizer.apply_gradients(zip(gradients, variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QO7aRwHqeEm"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, feature_num, epochs):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        data: (DataSet) train data set\n",
        "        feature_num: (int) number of feature\n",
        "        removed_feature: (str) feature not used. \n",
        "        epochs: (int)\n",
        "    \"\"\"\n",
        "    epochs = epochs   \n",
        "    latent_dim = LATENT_DIM\n",
        "    num_examples_to_generate = 16\n",
        "    random_vector_for_generation = tf.random_normal(\n",
        "        shape=[num_examples_to_generate, latent_dim]\n",
        "    )\n",
        "    model = TVAE(latent_dim, feature_num)\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(0.01)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        start_time = time.time()\n",
        "        for train_x in data:\n",
        "            gradients, loss = compute_gradients(model, train_x)\n",
        "            apply_gradients(optimizer, gradients, model.trainable_variables)\n",
        "        end_time = time.time()\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            for train_sample_x in data.make_one_shot_iterator():\n",
        "                train_loss(compute_loss(model, train_sample_x))\n",
        "            train_elbo = train_loss.result()\n",
        "            print(f'Epoch: {epoch}, duration: {end_time - start_time:.4f}s, train loss: {train_elbo}')\n",
        "    \n",
        "    x = pd.read_csv(\"/content/data/processed_data.csv\")\n",
        "    x = tf.convert_to_tensor(x.values)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "fi9RmQFC70PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = create_complete_data()\n",
        "model = train(data, feature_num=19, epochs=300)"
      ],
      "metadata": {
        "id": "69eFlcP76UBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretations"
      ],
      "metadata": {
        "id": "fLrVagAHBUJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps 1-6 are for feature importance\n",
        "#### Step 1"
      ],
      "metadata": {
        "id": "u4uXfCgYxLnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mus = []\n",
        "logvars = []\n",
        "mu_grads = []\n",
        "logvars_grads = []\n",
        "\n",
        "for train_x in data:\n",
        "    with tf.GradientTape(persistent=True) as g:\n",
        "        g.watch(train_x)\n",
        "        mean, logvar = model.encode(train_x)\n",
        "        mus.append(mean)\n",
        "        logvars.append(logvar)\n",
        "\n",
        "        mu_i_grads = []\n",
        "        logvars_i_grads = []\n",
        "        for i in range(mean.shape[1]):\n",
        "            mu_i_grads.append(g.gradient(mean[:, i], train_x))\n",
        "            logvars_i_grads.append(g.gradient(logvar[:, i], train_x))\n",
        "        \n",
        "        mu_grads.append(mu_i_grads)\n",
        "        logvars_grads.append(logvars_i_grads)"
      ],
      "metadata": {
        "id": "NCl8Kmiq7WvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2 "
      ],
      "metadata": {
        "id": "Jg5slWMSxOH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sj_mu_xn_list = []\n",
        "sj_sigma_xn_list = []\n",
        "\n",
        "for i in range(len(mu_grads)):\n",
        "   \n",
        "    abs_sij_mu_xn = tf.abs(mu_grads[i][0])\n",
        "    abs_sij_sigma_xn = tf.abs(logvars_grads[i][0])\n",
        "    \n",
        "    for j in range(1, len(mu_grads[i])):\n",
        "        abs_sij_mu_xn += tf.abs(mu_grads[i][j])\n",
        "        abs_sij_sigma_xn += tf.abs(logvars_grads[i][j])\n",
        "    \n",
        "    sj_mu_xn_list.append(abs_sij_mu_xn)\n",
        "    sj_sigma_xn_list.append(abs_sij_sigma_xn)\n",
        "\n",
        "sj_mu_xn = tf.concat(sj_mu_xn_list, axis=0)\n",
        "sj_sigma_xn = tf.concat(sj_sigma_xn_list, axis=0)\n",
        "\n",
        "print(f\"shape of mu_grad_x: {sj_mu_xn.shape}\")\n",
        "print(f\"shape of logvar_grad_x: {sj_sigma_xn.shape}\")"
      ],
      "metadata": {
        "id": "F6iCUNYrt2Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sj_xn = sj_mu_xn + sj_sigma_xn\n",
        "print(sj_xn.shape)"
      ],
      "metadata": {
        "id": "iGcW47mOwg4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grad_normalize_in(idx):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        idx (int): index of data point\n",
        "    \"\"\"\n",
        "    # normalization\n",
        "    sj_xn_normalize = sj_xn / tf.reduce_sum(sj_xn, axis=1, keepdims=True)\n",
        "    grad_in_idx = sj_xn_normalize[idx, :]\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    plt.bar(list(range(1, len(grad_in_idx)+1)), grad_in_idx)\n",
        "    plt.xticks(list(range(1, len(grad_in_idx)+1)))\n",
        "    plt.show()\n",
        "\n",
        "def plot_grad_in(idx):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        idx (int): index of data point\n",
        "    \"\"\"\n",
        "    grad_in_idx = sj_xn[idx, :]\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    plt.bar(list(range(1, len(grad_in_idx)+1)), grad_in_idx)\n",
        "    plt.xticks(list(range(1, len(grad_in_idx)+1)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fnLj1prSnXG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#relative local feature importance\n",
        "plot_grad_normalize_in(1)"
      ],
      "metadata": {
        "id": "ja_TMncxqgpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#local feature importance\n",
        "plot_grad_in(1)"
      ],
      "metadata": {
        "id": "wuf4OYggnLlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3"
      ],
      "metadata": {
        "id": "b57eJXnQxVE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sij_mu_xn_square = []\n",
        "sij_sigma_xn_square = []\n",
        "\n",
        "for j in range(len(mu_grads[0])):\n",
        "    \n",
        "    # the element in the following list is grad of a batch data\n",
        "    sij_mu_j_xn_square = []\n",
        "    sij_sigma_j_xn_square = []\n",
        "\n",
        "    for i in range(0, len(mu_grads)):\n",
        "        sij_mu_j_xn_square.append(mu_grads[i][j] ** 2)\n",
        "        sij_sigma_j_xn_square.append(logvars_grads[i][j] ** 2)\n",
        "    \n",
        "    sij_mu_xn_square.append(sij_mu_j_xn_square)\n",
        "    sij_sigma_xn_square.append(sij_sigma_j_xn_square)"
      ],
      "metadata": {
        "id": "ArEGSMbNrPzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sij_mu_sq = []\n",
        "sij_sigma_sq = []\n",
        "for j in range(len(sij_mu_xn_square)):\n",
        "    tmp_mu = tf.concat(sij_mu_xn_square[j], axis=0)\n",
        "    tmp_logvar = tf.concat(sij_sigma_xn_square[j], axis=0)\n",
        "\n",
        "    sij_mu_sq.append(tf.math.sqrt(tf.reduce_mean(tmp_mu, axis=0, keep_dims=True)))\n",
        "    sij_sigma_sq.append(tf.math.sqrt(tf.reduce_mean(tmp_logvar, axis=0, keep_dims=True)))"
      ],
      "metadata": {
        "id": "3XPrqeSAzjAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4"
      ],
      "metadata": {
        "id": "bzrTo-0B1M-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sj_mu_sq = tf.reduce_sum(tf.concat(sij_mu_sq, axis=0), axis=0, keepdims=True)\n",
        "sj_sigma_sq = tf.reduce_sum(tf.concat(sij_sigma_sq, axis=0), axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "jHsHEgl51Ei7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5"
      ],
      "metadata": {
        "id": "Pe-_EIjs1vjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sj_sq = sj_mu_sq + sj_sigma_sq"
      ],
      "metadata": {
        "id": "DCn7-wZg1xCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# global feature importance\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "plt.bar(list(range(19)), sj_sq.numpy().reshape(-1))\n",
        "plt.xticks(list(range(19)), [str(i) for i in range(1, 20)])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mxd59lCr15Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6"
      ],
      "metadata": {
        "id": "u4Wp9QD_2WW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# relative global feature importance\n",
        "a = sj_sq.numpy().reshape(-1)\n",
        "f = (a / a.sum()) * 100\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "plt.bar(list(range(19)), f)\n",
        "plt.xticks(list(range(19)), [str(i) for i in range(1, 20)])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWFnN7xJ2YiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 7 Feature interaction"
      ],
      "metadata": {
        "id": "w5XHn2E_7U_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "for it in data:\n",
        "    train_x.append(it)\n",
        "train_x = tf.concat(train_x, axis=0)\n",
        "print(f\"shape of train_x: {train_x.shape}\")"
      ],
      "metadata": {
        "id": "nyuqg6HWD7zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 7.1"
      ],
      "metadata": {
        "id": "ZT2ztpy39OeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as g:\n",
        "    with tf.GradientTape(persistent=True) as g2:\n",
        "        g.watch(train_x)\n",
        "        g2.watch(train_x)\n",
        "        mean, logvar = model.encode(train_x)\n",
        "\n",
        "        mjo_xn = []\n",
        "        it = 0    # just a temp variable\n",
        "        for i in range(mean.shape[1]):\n",
        "        \n",
        "            # first order grad\n",
        "            dmu_i_divide_dxon = g.gradient(mean[:, i], train_x)\n",
        "            dsigma_i_divide_dxon = g.gradient(logvar[:, i], train_x)\n",
        "        \n",
        "            # second order grad\n",
        "            it += tf.abs(g2.batch_jacobian(dmu_i_divide_dxon, train_x))\n",
        "            it += tf.abs(g2.batch_jacobian(dsigma_i_divide_dxon, train_x))\n",
        "            mjo_xn.append(it)"
      ],
      "metadata": {
        "id": "kofswlAd7WqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_jj_xn = 0\n",
        "\n",
        "for m in mjo_xn:\n",
        "    m_jj_xn += m\n",
        "\n",
        "print(f\"shape of m_jj_xn {m_jj_xn.shape}\")"
      ],
      "metadata": {
        "id": "tEWpTyPIYcOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_jj_reduce_mean = tf.reduce_mean(m_jj_xn, axis=0)\n",
        "\n",
        "mask = 1 - tf.eye(m_jj_reduce_mean.shape[0].value)\n",
        "\n",
        "m_jo = tf.reshape(m_jj_reduce_mean[tf.cast(mask, bool)], (1, -1))\n",
        "print(f\"shape of m_jo is: {m_jo.shape}\")"
      ],
      "metadata": {
        "id": "w5xmE8mNbDg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 7.2"
      ],
      "metadata": {
        "id": "v8rDkTz-fJhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_j_xn = tf.reduce_sum(m_jj_xn * tf.expand_dims((1 - tf.eye(m_jj_xn.shape[1].value)), axis=0), axis=2)\n",
        "print(f\"shape of m_j_xn: {m_j_xn.shape}\")"
      ],
      "metadata": {
        "id": "7mIkPbpifMFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mjxn_in(idx):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        idx (int): index of data point\n",
        "    \"\"\"\n",
        "    grad_in_idx = m_j_xn.numpy()[idx, :]\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    plt.bar(list(range(1, len(grad_in_idx)+1)), grad_in_idx)\n",
        "    plt.xticks(list(range(1, len(grad_in_idx)+1)))\n",
        "    plt.show()\n",
        "\n",
        "plot_mjxn_in(1)"
      ],
      "metadata": {
        "id": "eIhANXZG5CNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_j = tf.reduce_mean(m_j_xn, axis=0)\n",
        "print(f\"shape of m_j: {m_j.shape}\")"
      ],
      "metadata": {
        "id": "KvcN7S04fi2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 8))\n",
        "plt.bar(list(range(len(m_j))), m_j)\n",
        "plt.xticks(list(range(19)), [str(i+1) for i in range(19)])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RzMkJudYgPn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}